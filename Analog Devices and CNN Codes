# THIS CODE IS FOR ROTATING THE STEPPER MOTORS WHEN THE PLASTIC OBJECT IS DETECTED.
# THE PRESENT CODE WORKS WHEN TWO PUSH BUTTONS ARE CONNECTED TO EACH MOTOR AND ONE BUTTON IS FOR FORWARD AND THE OTHER BUTTON IS FOR BACKWARD MOVEMENT OF THE MOTOR.

#include <Stepper.h>

// Define steps per revolution for 28BYJ-48 motor
const int stepsPerRevolution = 2048;

// Motor 1: IN1-IN4 -> pins 2,3,4,5
Stepper motor1(stepsPerRevolution, 2, 4, 3, 5);
// Motor 2: IN1-IN4 -> pins 13,12,11,10
Stepper motor2(stepsPerRevolution, 13, 11, 12, 10);

// Buttons
const int motor1ForwardButton = 6;
const int motor1ReverseButton = 7;
const int motor2ForwardButton = 8;`
const int motor2ReverseButton = 9;

void setup() {
  // Set all button pins as input with internal pull-up
  pinMode(motor1ForwardButton, INPUT_PULLUP);
  pinMode(motor1ReverseButton, INPUT_PULLUP);
  pinMode(motor2ForwardButton, INPUT_PULLUP);
  pinMode(motor2ReverseButton, INPUT_PULLUP);

  // Set speed for both motors
  motor1.setSpeed(10); // adjust as needed
  motor2.setSpeed(10);
}

void loop() {
  // Read button states
  int m1Forward = digitalRead(motor1ForwardButton);
  int m1Reverse = digitalRead(motor1ReverseButton);
  int m2Forward = digitalRead(motor2ForwardButton);
  int m2Reverse = digitalRead(motor2ReverseButton);

  // Motor 1 control
  if (m1Forward == LOW) {
    motor1.step(3);
  }
  if (m1Reverse == LOW) {
    motor1.step(-3);
  }

  // Motor 2 control
  if (m2Forward == LOW) {
    motor2.step(3);
  }
  if (m2Reverse == LOW) {
    motor2.step(-3);
  }
}

# THIS CODE IS TO RUN ON THE ESP32-CAM MODULE. WHAT THIS CODE DOES IS, IT MAKES THE CAM MODULE CAPTURE THE IMAGE WHEN DISTANCE IS DETECTED BY ULTRASONIC SENSOR AND GIVES OUTPUT.
#
//#include "TensorFlowLite_ESP32.h"
#include "esp_camera.h"
#include "tensorflow/lite/micro/micro_interpreter.h"
//#include "tensorflow/lite/micro/micro_error_reporter.h"
#include "tensorflow/lite/schema/schema_generated.h"
#include "tensorflow/lite/version.h"
//#include <tensorflow/lite/version.h>
#include "Ultrasonic.h"
#include <Stepper.h>
#include "tflite_model.h"  // Include the TensorFlow Lite Model Header File

#define TRIG_PIN 12
#define ECHO_PIN 13
#define STEPS 2048
#define BUZZER_PIN 14  // Buzzer Pin Definition
Stepper motor(STEPS, 15, 2, 4, 16);
Ultrasonic ultrasonic(TRIG_PIN, ECHO_PIN);

// Camera Pin Configuration
#define PWDN_GPIO_NUM     -1
#define RESET_GPIO_NUM    -1
#define XCLK_GPIO_NUM     0
#define SIOD_GPIO_NUM     26
#define SIOC_GPIO_NUM     27
#define Y9_GPIO_NUM       35
#define Y8_GPIO_NUM       34
#define Y7_GPIO_NUM       39
#define Y6_GPIO_NUM       36
#define Y5_GPIO_NUM       21
#define Y4_GPIO_NUM       19
#define Y3_GPIO_NUM       18
#define Y2_GPIO_NUM       5
#define VSYNC_GPIO_NUM    25
#define HREF_GPIO_NUM     23
#define PCLK_GPIO_NUM     22

tflite::MicroErrorReporter micro_error_reporter;
tflite::ErrorReporter* error_reporter = &micro_error_reporter;

// Allocate Memory for Model
const tflite::Model* model = tflite::GetModel(tflite_model);
constexpr int tensor_arena_size = 50 * 1024;
uint8_t tensor_arena[tensor_arena_size];

tflite::MicroInterpreter interpreter(model, tensor_arena, tensor_arena_size, error_reporter);

void setup() {
  Serial.begin(115200);
  pinMode(BUZZER_PIN, OUTPUT);  // Initialize Buzzer Pin
  
  camera_config_t config;
  config.ledc_channel = LEDC_CHANNEL_0;
  config.ledc_timer = LEDC_TIMER_0;
  config.pin_d0 = Y2_GPIO_NUM;
  config.pin_d1 = Y3_GPIO_NUM;
  config.pin_d2 = Y4_GPIO_NUM;
  config.pin_d3 = Y5_GPIO_NUM;
  config.pin_d4 = Y6_GPIO_NUM;
  config.pin_d5 = Y7_GPIO_NUM;
  config.pin_d6 = Y8_GPIO_NUM;
  config.pin_d7 = Y9_GPIO_NUM;
  config.xclk_freq_hz = 20000000;
  config.pixel_format = PIXFORMAT_GRAYSCALE;
  config.frame_size = FRAMESIZE_96X96;
  config.jpeg_quality = 10;
  config.fb_count = 2;

  esp_camera_init(&config);
  interpreter.AllocateTensors();
}

void loop() {
  float distance = ultrasonic.read();

  if (distance <= 5.0) {
    Serial.println("Object Detected... Capturing Image...");

    camera_fb_t *fb = esp_camera_fb_get();
    if (!fb) {
      Serial.println("Failed to capture image!");
      return;
    }

    for (int i = 0; i < 96 * 96; i++) {
      interpreter.input(0)->data.f[i] = (fb->buf[i] / 255.0);
    }

    interpreter.Invoke();
    float result = interpreter.output(0)->data.f[0];

    if (result > 0.5) {
      Serial.println("Plastic Detected! Rotating Motor...");
      motor.step(512);
      delay(1000);
    } else {
      Serial.println("No Plastic Detected!");
      digitalWrite(BUZZER_PIN, HIGH);
      delay(2000);
      digitalWrite(BUZZER_PIN, LOW);
    }
    
    esp_camera_fb_return(fb);
  }

  delay(1000);
}

#THIS CODE IS FOR RUNNING THE INTERFACE FOR YOLOv8 ON THE RASPBERRY PI VNC VIEWER. tHIS CODE FORMS BOXES AROUND THE OBJECTS THAT ARE DETECTED AND DISPLAYS THE NAME OF THE OBJECT ON TOP OF THE OBJEECTS.
from ultralytics import YOLO
import cv2

# Load the model - using a lightweight version for Raspberry Pi
model = YOLO("yolov8n.pt")

# Open webcam (adjust if your cam is at /dev/video1, use 1 instead of 0)
cap = cv2.VideoCapture(0)

if not cap.isOpened():
    print("Failed to open webcam")
    exit()

while True:
    ret, frame = cap.read()
    if not ret:
        break

    # Run YOLOv8 inference
    results = model(frame)

    # Plot results
    annotated_frame = results[0].plot()

    # Show the result
    cv2.imshow("YOLOv8 Inference", annotated_frame)

    if cv2.waitKey(1) & 0xFF == ord("q"):
        break

cap.release()
cv2.destroyAllWindows()

#THIS CODE USES THE YOLO MODEL TO SEE WHETHER THE DETECTED OBJECT IS PLASTIC OR NOT.

import cv2
from ultralytics import YOLO
import os
import time

model = YOLO('yolov8n.pt')  # or your custom-trained model
processed = set()

while True:
    for filename in os.listdir('/var/www/html/uploads/'):
        if filename not in processed:
            img_path = f'/var/www/html/uploads/{filename}'
            results = model(img_path)
            for result in results:
                if 'plastic' in result.names.values():
                    print(f'Plastic detected in {filename}')
            processed.add(filename)
    time.sleep(5)
